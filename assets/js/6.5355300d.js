(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{352:function(t,a,s){"use strict";s.r(a);var e=s(42),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"table-of-content"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#table-of-content"}},[t._v("#")]),t._v(" Table of Content")]),t._v(" "),s("p"),s("div",{staticClass:"table-of-contents"},[s("ul",[s("li",[s("a",{attrs:{href:"#abbreviations"}},[t._v("Abbreviations")])]),s("li",[s("a",{attrs:{href:"#abstract"}},[t._v("Abstract")])]),s("li",[s("a",{attrs:{href:"#chapter-1-introduction"}},[t._v("Chapter 1: Introduction")])]),s("li",[s("a",{attrs:{href:"#chapter-2-motivation-and-problem-statement"}},[t._v("Chapter 2: Motivation and Problem Statement")]),s("ul",[s("li",[s("a",{attrs:{href:"#_2-1-motivation"}},[t._v("2.1: Motivation")])]),s("li",[s("a",{attrs:{href:"#_2-2-problem-statement"}},[t._v("2.2: Problem Statement")])])])]),s("li",[s("a",{attrs:{href:"#chapter-3-literature-review"}},[t._v("Chapter 3: Literature Review")])]),s("li",[s("a",{attrs:{href:"#chapter-4-materials-and-methods"}},[t._v("Chapter 4: Materials and Methods")]),s("ul",[s("li",[s("a",{attrs:{href:"#_4-1-materials"}},[t._v("4.1: Materials")])]),s("li",[s("a",{attrs:{href:"#_4-2-methods"}},[t._v("4.2: Methods")])])])]),s("li",[s("a",{attrs:{href:"#chapter-5-implementation-details"}},[t._v("Chapter 5: Implementation Details")]),s("ul",[s("li",[s("a",{attrs:{href:"#_5-1-snippets-of-model-training-code"}},[t._v("5.1: Snippets of Model Training Code")])]),s("li",[s("a",{attrs:{href:"#_5-2-snippets-of-app-user-interface"}},[t._v("5.2: Snippets of App User Interface")])])])])])]),s("p"),t._v(" "),s("h2",{attrs:{id:"abbreviations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#abbreviations"}},[t._v("#")]),t._v(" Abbreviations")]),t._v(" "),s("p",[s("strong",[t._v("ML")]),t._v(" Machine Learning"),s("br"),t._v(" "),s("strong",[t._v("DL")]),t._v(" Deep Learning"),s("br"),t._v(" "),s("strong",[t._v("CNN")]),t._v(" Convolutional Neural Network"),s("br"),t._v(" "),s("strong",[t._v("DCNN")]),t._v(" Deep Convolutional Neural Network"),s("br"),t._v(" "),s("strong",[t._v("ILSVRC")]),t._v(" ImageNet Large Scale Visual Recognition Challenge"),s("br"),t._v(" "),s("strong",[t._v("VGG")]),t._v(" Visual Geometry Group "),s("strong",[t._v("(")]),t._v(" Convolutional neural network architecture "),s("strong",[t._v(")")]),s("br"),t._v(" "),s("strong",[t._v("COCO")]),t._v(" Common Objects in Context")]),t._v(" "),s("h2",{attrs:{id:"abstract"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#abstract"}},[t._v("#")]),t._v(" Abstract")]),t._v(" "),s("p",[t._v("With the increase in population, the needs have also been increased. As agriculture is a vital source for providing food, whereas crop ailments are major commination to agriculture, and their early detection remains strenuous over the globe due to insufficient technology, agricultural organizations are unable to reach farmers in time for necessary precautionary measures. As a result, farmers have to suffer from compromised lower crop yield. Many machine learning models were used to detect and identify diseases of plants but, after the advancement in Deep Learning, this field seems to have great potential concerning improved accuracy. The combination of advancements in computer vision and the global smartphone penetration made possible by deep learning to provide a mobile-phone-based system to diagnose diseases. Using a public data-set of "),s("strong",[t._v("87,900")]),t._v(" photos of healthy and diseased leaves, several models were trained to identify "),s("strong",[t._v("14")]),t._v(" crops and the presence or absence of "),s("strong",[t._v("26")]),t._v(" diseases, with the best performance reaching a "),s("strong",[t._v("98.58%")]),t._v(" on the retained dataset, which demonstrates the practicality of our perspective. Generally, the methodology of training deep convolutional neural networks on exceptionally huge and publicly accessible image data-sets presents a straightforward path towards a massive global diagnosis of mobile-phone-assisted crop disease.")]),t._v(" "),s("h2",{attrs:{id:"chapter-1-introduction"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chapter-1-introduction"}},[t._v("#")]),t._v(" Chapter 1: Introduction")]),t._v(" "),s("p",[t._v("Earth is occupying more than 7 billion people. The number is increasing gradually.\nWith a persistent increase in population, it is understood that basic life necessities\nare also increasing in which food is on top of the list. The increasing population\nhas also eaten up the land, and the area for agricultural land is shrinking up.\nSo we have to get an adequate amount of food from the land available. Food\nsustainability, however, remains endanger by a variety of factors which includes\nclimate change [5], plant diseases [23] and others. When the plants are growing up,\nthey are attacked by diseases which clearly means a compromised lower crop yield.\nUnfortunately, smallholder farmers have to face the disastrous consequences whose\nincome entirely depends upon crops. Yield. The major agricultural production\ncomes from smallholder farmers [9], and they have to suffer approximately 50%\nyield loss due to climate change, pest attack, and diseases. Acknowledging these\nproblems, various attempts have been made to avert or lower the loss of crop yield.\nTo prevent the disease, it is crucial to detect the disease at an early stage. And\nefficient disease management is a very crucial step in this regard. Agricultural\norganizations have been working for disease detection at an early stage at local\nclinics. During the past decades the world has totally turned into ”Global Village”\nand because of that enormous data is available online including information on\ndisease diagnosis [11] and the leverage of which is internet penetration worldwide.\nMore recently, mobile phone technology incredibly has become famous due to the\nproliferation of mobile-based tools in all parts of the world. All these factors\nescort us to a point where disease detection is technically feasible and available at\nan unparalleled scale. Unlike other countries, Pakistan lacks modern technology\ndue to which, we are unable to detect diseases in time and to reach farmers in\norder to raise awareness about rehabilitation. The blue-collar approaches make\nit very slow for policy-making organizations to gather data and draw results for\nimmediate movement. The intensity behind this research work is to dispense\nan efficient system that can detect the disease straight-away whether a farmer\nor agricultural organization uses it. We intended to develop mobile as well as\na web-based tool using deep learning for the detection of crop diseases. Deep\nlearning has proved its worth successfully in many different domains such as\nend-to-end learning. Now we are going to demonstrate the technical feasibility of our\nproposed approach by utilizing 87,900 images on healthy and infected leaves of\ncrop plants that are openly available on the online system PlantVillage [2].")]),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/ExampleDatasetImages.jpg",alt:"Sample leaf images from the dataset",title:"Sample leaf images from the dataset"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 1.1:")]),t._v(" Sample leaf images from the dataset")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("A DCNN includes the mapping between an input to an output. Deep learning\nis probability-based means it never gives us the definite answer however it gives\nus the probabilities. The term CNN itself stipulates that a mathematical function called convolution is used within the network. Convolution is a specific type\nmathematical operation on two functions which produces a third function that\nexpresses how another changes one’s form. A CNN consists of two main input and\noutput layers, and multiple hidden layers. Typically the hidden layers consist of\na series of convolutionary layers. The activation function is commonly a Rectified\nLinear Units (RELU). The purpose of RELU is to normalize the values after the\napplication of convolution to convert the values in a specific range. Additional\nconvolutions such as pooling, fully connected layers and normalization layers follow the RELU. Pooling is to choose the best or one thing out of the pool of things.\nThe nodes in neural networks are computational units which take weighted inputs\nfrom the incoming edges and provide an outgoing edge with numerical output.\nnode enumerates an output value by adding a specific function to the previous\nlayer’s input values. In a neural network, model learning progresses through iterative changes to these weights and biases. DCNN is learned by changing network\nparameters in such a way as to improve mapping during the training. For thepurpose of plant disease identification, we needed a large and verified data-set of\nhealthy and diseased images to train an accurate image classifier, but such dataset\ndid not exist until very recently, and even small dataset were not publicly available. In order to tackle this issue, the PlantVillage project began to collect a large\ndataset of diseased and healthy crop plants and made them available publicly. We\nannounce here on the classification of 26 diseases (presence or absence) in 14 crop\nspecies using 87,900 with deep learning (DL).")]),t._v(" "),s("h2",{attrs:{id:"chapter-2-motivation-and-problem-statement"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chapter-2-motivation-and-problem-statement"}},[t._v("#")]),t._v(" Chapter 2: Motivation and Problem Statement")]),t._v(" "),s("h3",{attrs:{id:"_2-1-motivation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-motivation"}},[t._v("#")]),t._v(" 2.1: Motivation")]),t._v(" "),s("p",[t._v("With the increase in population, the needs have also been increased. As agriculture is the vital source for providing food but, unfortunately, because of lack the\nmodern technology, the agricultural organization are unable to reach farmers in\ntime for necessary precautionary measures. As a results farmers have to suffer\nfrom compromised lower crop yield. We are aimed to work for a solution that can\nprevent farmers from suffering a loss to some extent.")]),t._v(" "),s("h3",{attrs:{id:"_2-2-problem-statement"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-problem-statement"}},[t._v("#")]),t._v(" 2.2: Problem Statement")]),t._v(" "),s("p",[t._v("Plant disease affects not only the production of human food but also natural\nsystems. The majority of smallholder farmers do not have access to the resources\nthat can identify the diseases accurately and timely. Due to the lack of timely and\naccurate agricultural information, they have to suffer from lower crop yield.")]),t._v(" "),s("h2",{attrs:{id:"chapter-3-literature-review"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chapter-3-literature-review"}},[t._v("#")]),t._v(" Chapter 3: Literature Review")]),t._v(" "),s("p",[t._v("The Deep Learning (DL) is subcategory of ML. This field is still evolving. Machine\nLearning has made enormous evolution in the past few years. Many advances were\nfound in the first phase, such as handwritten text recognition, back-propagation\nand resolving training problems. In the second phase was to develop algorithms\nfor health-sectors, text-recognition, earthquake-predictions, marketing, finance,\nimage-recognition, and object detection. In 2012 a deep convolutionary neural\nnetwork accomplished a top-5 error of 15.3% when classifying images into 1000\npossible categories [1]. In the next three years, numerous advances in convolutionary neural networks reduced the error rate to 3.57. With the passage of time as\nDeep Learning architectures started to evolve, researchers applied them to classification, segmentation, object detection, video processing, natural language processing, image recognition, and speech recognition. Different agriculture application\nhas also been developed using these architectures. For example, Leaf counting was\nperformed using Deep CNN with average accuracy of 95% [25]. Leaf classification\nwas performed using deep convolutional neural network classifier among 32 different species with average accuracy of 97.3% [7]. Fruit counting was performed by\nusing simulated deep convolutional neural network with an average accuracy of\n91% [19]. Classification of land cover and crop type was performed by using deep\nlearning classifier with accuracy of crop type identification of 95% [18]. Identification of plants was performed by using Deep convolutional neural network [10, 16].\nIn [26] identification of plants was performed among 100 different species utilizing\n10,000 images using deep learning with an accuracy of 91.78%. In addition deep\nlearning techniques are also used in for crucial tasks such as crop plant disease\nidentification and classification which is main topic of this thesis. For example,\nin [20] plant disease detection was performed using deep convolutional neural network classifier. To sum up, used DL Architectures are shown in the table along with the selected plants and their results.")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("Deep Learning Techniques")]),t._v(" "),s("th",[t._v("Dataset")]),t._v(" "),s("th",[t._v("Used Plants")]),t._v(" "),s("th",[t._v("Accuracy")]),t._v(" "),s("th",[t._v("Reference")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("Convolutional Neural Network")]),t._v(" "),s("td",[t._v("Plant Village ")]),t._v(" "),s("td",[t._v("Maize")]),t._v(" "),s("td",[t._v("92.85%")]),t._v(" "),s("td",[t._v("[21]")])]),t._v(" "),s("tr",[s("td",[t._v("LeNet")]),t._v(" "),s("td",[t._v("Plant Village ")]),t._v(" "),s("td",[t._v("Banana")]),t._v(" "),s("td",[t._v("98.54%")]),t._v(" "),s("td",[t._v("[4]")])]),t._v(" "),s("tr",[s("td",[t._v("Alex-Net, VGG16, VGG-19, Squeeze-Net, Goog-LeNet, Inception-v-3, Inception-ResNet-v-2, ResNet-50, Resnet-101 ")]),t._v(" "),s("td",[t._v("Real Field Dataset")]),t._v(" "),s("td",[t._v("Apricot, Walnut, Peach, Cherry ")]),t._v(" "),s("td",[t._v("97.14%")]),t._v(" "),s("td",[t._v("[24]")])]),t._v(" "),s("tr",[s("td",[t._v("Inception-v-3 ")]),t._v(" "),s("td",[t._v("Experimental Field Dataset ")]),t._v(" "),s("td",[t._v("Cassava ")]),t._v(" "),s("td",[t._v("93%")]),t._v(" "),s("td",[t._v("[3]")])]),t._v(" "),s("tr",[s("td",[t._v("Convolutional Neural Network")]),t._v(" "),s("td",[t._v("Images Taken From The Research Center ")]),t._v(" "),s("td",[t._v("Cucumber ")]),t._v(" "),s("td",[t._v("82.3%")]),t._v(" "),s("td",[t._v("[8]")])]),t._v(" "),s("tr",[s("td",[t._v("Super Resolution Convolutional Neural Network (SCRNN)")]),t._v(" "),s("td",[t._v("Plant Village ")]),t._v(" "),s("td",[t._v("Tomato ")]),t._v(" "),s("td",[t._v("90%")]),t._v(" "),s("td",[t._v("[15]")])]),t._v(" "),s("tr",[s("td",[t._v("Caffe-Net")]),t._v(" "),s("td",[t._v("Downloaded From The Internet ")]),t._v(" "),s("td",[t._v("Pear, cherry, peach, apple, grapevine ")]),t._v(" "),s("td",[t._v("96.3%")]),t._v(" "),s("td",[t._v("[22]")])]),t._v(" "),s("tr",[s("td",[t._v("Resnet-50, Inception-V-2, Mobile-Net-V-1 ")]),t._v(" "),s("td",[t._v("Real Environment ")]),t._v(" "),s("td",[t._v("Banana ")]),t._v(" "),s("td",[t._v("99% of ResNet-50")]),t._v(" "),s("td",[t._v("[17]")])]),t._v(" "),s("tr",[s("td",[t._v("Mobile-Net, Modified-Mobile-Net, Reduced-Mobile-Net")]),t._v(" "),s("td",[t._v("Plant Village dataset")]),t._v(" "),s("td",[t._v("24 Types Of Plants")]),t._v(" "),s("td",[t._v("98.34% of reduced MobileNet ")]),t._v(" "),s("td",[t._v("[14]")])])])]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Table 3.1:")]),t._v(" DL Architectures along with selected plant species and results")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("From this table, we can conclude that while some Deep Learning Architectures/-\nModels have been developed for the identification of the diseases of plants but this\nis still a prolific research field and should lead to improvements for better plant\ndisease identification. So we needed a large and verified data set of healthy and\ndiseased images to train an accurate image classifier for plant disease diagnosis,\nbut such a dataset did not exist until very recently. Plant Village collected a huge\ndataset of 87,900 images of plant health to enable the development of smartphone\nassisted disease diagnosis and made it publicly and freely available [12].")]),t._v(" "),s("h2",{attrs:{id:"chapter-4-materials-and-methods"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chapter-4-materials-and-methods"}},[t._v("#")]),t._v(" Chapter 4: Materials and Methods")]),t._v(" "),s("h3",{attrs:{id:"_4-1-materials"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-materials"}},[t._v("#")]),t._v(" 4.1: Materials")]),t._v(" "),s("p",[t._v("Our dataset is consists of 87,900 pictures of healthy and diseased plant leaves. All\nthe images in the dataset were taken at experimental research stations affiliated\nwith Land Grant Universities in the USA (Penn State, Florida State, Cornell, and\nothers) [12]. These images consist of 26 major crop diseases (4 bacterial diseases,\n17 Fungal diseases, 2 viral diseases, 2 mold diseases, and 1 disease caused by a\nmite). These images also have 12 healthy leaves of 12 crop species that are not\nvisibly affected by a disease. Table 4.1 Summarizes the dataset.")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("Crop")]),t._v(" "),s("th",[t._v("Classes")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("Apple")]),t._v(" "),s("td",[t._v("Apple-Healthy, Apple-Cedar-Rust, Apple-Black-Rot, Apple-Scab")])]),t._v(" "),s("tr",[s("td",[t._v("Raspberry")]),t._v(" "),s("td",[t._v("Raspberry-Healthy")])]),t._v(" "),s("tr",[s("td",[t._v("Soybean")]),t._v(" "),s("td",[t._v("Soybean-Healthy")])]),t._v(" "),s("tr",[s("td",[t._v("Squash")]),t._v(" "),s("td",[t._v("Squash-Powdery-Mildew")])]),t._v(" "),s("tr",[s("td",[t._v("Strawberry")]),t._v(" "),s("td",[t._v("Strawberry-Leaf-Scorch, Strawberry-Healthy")])]),t._v(" "),s("tr",[s("td",[t._v("Tomato")]),t._v(" "),s("td",[t._v("\n        Tomato-Healthy, Tomato-Late-Blight, TomatoBacterial-Spot,\n        Tomato-Early-Blight, TomatoLeaf-Mold, Tomato-Septoria-Leaf-Spot,\n        TomatoMosaic-Virus, Tomato-Two-Spotted-Spider-Mite, Tomato-Target-Spot,\n        Tomato-Yellow-Leaf-CurlVirus\n      ")])]),t._v(" "),s("tr",[s("td",[t._v("Potato")]),t._v(" "),s("td",[t._v("Potato-Early-Blight, Potato-Late-Blight, PotatoHealthy")])]),t._v(" "),s("tr",[s("td",[t._v("Blueberry")]),t._v(" "),s("td",[t._v("Blueberry-Healthy")])]),t._v(" "),s("tr",[s("td",[t._v("Cherry")]),t._v(" "),s("td",[t._v("Cherry-Healthy, Cherry-Powdery-Mildew")])]),t._v(" "),s("tr",[s("td",[t._v("Corn")]),t._v(" "),s("td",[t._v("\n        Corn-Healthy, Corn-Common-Rust, Corn-Gray-Leaf Spot,\n        Corn-Northern-Leaf-Blight\n      ")])]),t._v(" "),s("tr",[s("td"),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",[t._v("Grape")]),t._v(" "),s("td",[t._v("\n        Grape-Healthy, Grape-Leaf-Blight, Grape-BlackRot,\n        Grape-Black-Measles(Esca)\n      ")])]),t._v(" "),s("tr",[s("td",[t._v("Orange")]),t._v(" "),s("td",[t._v("Orange-Huanglongbing (Citrus-Greening)")])]),t._v(" "),s("tr",[s("td",[t._v("Peach")]),t._v(" "),s("td",[t._v("Peach-Healthy, Peach-Bacterial-Spot")])]),t._v(" "),s("tr",[s("td",[t._v("Bell-Pepper")]),t._v(" "),s("td",[t._v("Bell-Pepper-Bacterial-Spot, Bell-Pepper-Healthy")])])])]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Table 4.1:")]),t._v(" List of Crops with their respective classes in the Dataset.")]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"_4-2-methods"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-methods"}},[t._v("#")]),t._v(" 4.2: Methods")]),t._v(" "),s("p",[t._v("Since these diseases can severely affect plants, we landed up with four different\nmodels for 38 different classes (Table 4.1) to achieve maximum accuracy. Blueprint\nof our proposed system for disease detection is showed in the figure 4.1.")]),t._v(" "),s("p",[t._v("To train the model, we focused on 4 different architectures, namely VGG16,\nResnet152, MobileNet, and MobileNetV2.")]),t._v(" "),s("p",[t._v("VGG16 was proposed by Andrew Zisserman and Karen Simonyan of the Visual\nGeometry Community Lab at Oxford University. This model secured 1st and 2nd\nplace in ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2014.\nThe VGG16 network is trained on an ImageNet dataset which has 14 million\nimages and 1000 classes, and this model achieves 92.7% top-5 test accuracy.")]),t._v(" "),s("p",[t._v("Resnet was proposed by Microsoft Research Asia [13] and won the ImageNet\nLarge Scale Visual Recognition Challenge (ILSVRC) and MS-COCO competition in 2015. ResNet architecture has several variants all of them have the similar\nconcept but have different number of layers, for example ResNet-18, ResNet-50,\nResNet-101 and so on. The name Resnet followed by numbers simply insinuate\nthe Resnet architecture witch has number of layers of neural network. The main\nidea manoeuvred in these models, residual network connections, is found to greatly\nenhance gradient flow, thus enabling the training of tens or even hundreds of layers\nof much deeper models.")]),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/fyp_model_image.jpeg",alt:"Blueprint of our proposed system for disease detection",title:"Blueprint of our proposed system for disease detection"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.1:")]),t._v(" Blueprint of our proposed system for disease detection")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("MobileNet is a model built primarily from depthwise separable convolutions to\ncreate lightweight deep convolutional neural networks and provides an efficient\nmodel for smartphone and integrated vision applications [6].")]),t._v(" "),s("p",[t._v("To train these models we used Google Colaboratory framework. Google Colab\nis a free cloud service created by Google, in which the person who has a Gmail\naccount can write, execute codes for Machine learning as well as for Deep learning.\nIn Google Colab different runtime environments and Various versions of python\nare available. It can also download large datasets to google drive at higher speed\ndirectly from the servers. With Google Colab, you can also mount your drive and it\ncan fetch the appropriate file after the authentication. The most important feature\nof Google Colab that distinguishes it from other free cloud services is it provides\nGPU and it is totally free. To summarize, we have 4 experimental configurations\nin total, which are described in the next section")]),t._v(" "),s("h4",{attrs:{id:"_4-2-1-experiment-1"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-1-experiment-1"}},[t._v("#")]),t._v(" 4.2.1: Experiment # 1")]),t._v(" "),s("p",[t._v("In this experiment, we used a python deep learning library called PyTorch, and\nthe model we used in this experiment is Resnet152. We used transfer learning to\ntrain the model because it always yields better results. This experiment runs for\na total of 50 epochs and achieves testing accuracy of 98.5%.")]),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/fyp-model-accuracy-pytorch.png",alt:"Model Accuracy",title:"Model Accuracy"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.2:")]),t._v(" Model Accuracy")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/fyp-model-loss-pytorch.png",alt:"Model Loss",title:"Model Loss"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.3:")]),t._v(" Model Loss")]),t._v(" "),s("hr"),t._v(" "),s("h4",{attrs:{id:"_4-2-2-experiment-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-2-experiment-2"}},[t._v("#")]),t._v(" 4.2.2: Experiment # 2")]),t._v(" "),s("p",[t._v("In this experiment, we used a python deep learning library called TensorFlow, and\nwe created a custom model. This experiment runs for a total of 80 epochs and\nachieves an accuracy of 94.72%.")]),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/precision-recall-accuracy-f1-score-custome-model.png",alt:"Accuracy of the classifier for all classes",title:"Accuracy of the classifier for all classes"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Accuracy of the classifier for all classes")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"chapter-5-implementation-details"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chapter-5-implementation-details"}},[t._v("#")]),t._v(" Chapter 5: Implementation Details")]),t._v(" "),s("p",[t._v("The very first was to gather the data and train the model to get the results. After\nthe collection of the dataset which is consisted of 87,900 different plant images, we\ndivided the dataset into train-test splits of 25-75, 50-50, and 25-75. We made these\nsplits to get a sense of how our proposed approach will perform on the unseen data\nand also keep track of if our proposed approach is underfitting or overfitting. After\ntraining the model with the best performance reaching a 98.58% on a held-out test\nset we developed an API using Flask for this model to interact with our mobile\napplication. After the development of the API, we developed a mobile application\nto interact with the API which interacts with the model to give the final results.")]),t._v(" "),s("h3",{attrs:{id:"_5-1-snippets-of-model-training-code"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-snippets-of-model-training-code"}},[t._v("#")]),t._v(" 5.1: Snippets of Model Training Code")]),t._v(" "),s("p",[t._v("Here are some snippets of our code to train the model.")]),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optim\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("functional "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" F\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torchvision "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datasets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" models\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torchvision\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" collections "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OrderedDict\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("autograd "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Variable\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" PIL "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Image\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" lr_scheduler\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.1:")]),t._v(" Libraries used in the model training")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("data_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/content/DataSet'")]),t._v("\ntrain_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/train'")]),t._v("\nvalid_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/val'")]),t._v("\nnThreads "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\nbatch_size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),t._v("\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.2:")]),t._v(" Load the dataset")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("data_transforms "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Compose"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RandomRotation"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RandomResizedCrop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RandomHorizontalFlip"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ToTensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.485")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.456")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.406")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.229")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.225")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Compose"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Resize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CenterCrop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ToTensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.485")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.456")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.406")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.229")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.225")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\ndata_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/content/DataSet'")]),t._v("\nimage_datasets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" datasets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ImageFolder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("os"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                          data_transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\ndataloaders "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataLoader"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("image_datasets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("batch_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                             shuffle"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_workers"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n              "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\ndataset_sizes "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("image_datasets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nclass_names "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" image_datasets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("classes\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.3:")]),t._v(" Applying Data Augmentation")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" models"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resnet152"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pretrained"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" param "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    param"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" collections "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OrderedDict\n\nclassifier "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("OrderedDict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fc1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2048")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fc2'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("39")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'output'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("LogSoftmax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nmodel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" classifier\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.4:")]),t._v(" Building the Classifier")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("train_model")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scheduler"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    since "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    best_model_wts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" copy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deepcopy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    best_acc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Epoch {}/{}'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epoch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_epochs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" phase "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" phase "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                scheduler"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n\n            running_loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v("\n            running_corrects "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("phase"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zero_grad"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_grad_enabled"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("phase "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    outputs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("outputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    _"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" preds "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("outputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" phase "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backward"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                running_loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" inputs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                running_corrects "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("preds "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            epoch_loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" running_loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" dataset_sizes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("phase"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            epoch_acc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" running_corrects"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("double"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" dataset_sizes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("phase"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{} Loss: {:.4f} Acc: {:.4f}'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                phase"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epoch_acc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" phase "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" epoch_acc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" best_acc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                best_acc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" epoch_acc\n                best_model_wts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" copy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deepcopy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    time_elapsed "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" since\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Training complete in {:.0f}m {:.0f}s'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        time_elapsed "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("//")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" time_elapsed "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Best valid accuracy: {:4f}'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_acc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_state_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_model_wts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" model\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.5:")]),t._v(" Function to train the model")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("num_epochs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),t._v("\n\ncriterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("NLLLoss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\noptimizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.001")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexp_lr_scheduler "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lr_scheduler"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("StepLR"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" step_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gamma"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel_ft "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exp_lr_scheduler"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("num_epochs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.6:")]),t._v(" : Start Training")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("test")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  accuracy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n  model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    images "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    output "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("forward"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ps "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    equality "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    accuracy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" equality"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type_as"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("FloatTensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Testing Accuracy: {:.3f}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("accuracy"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'val'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ntest"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.7:")]),t._v(" Model validation after Training")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-py extra-class"},[s("pre",{pre:!0,attrs:{class:"language-py"}},[s("code",[t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("class_to_idx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("class_to_idx\nmodel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" num_epochs\ncheckpoint "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'input_size'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'batch_size'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" dataloaders"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch_size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'output_size'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("39")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'state_dict'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data_transforms'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" data_transforms"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'optimizer_dict'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state_dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'class_to_idx'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("class_to_idx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'epoch'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epochs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\ntorch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpoint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'plants9615_checkpoint.pth'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 5.8:")]),t._v(" Saving the model for Further use")]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"_5-2-snippets-of-app-user-interface"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-snippets-of-app-user-interface"}},[t._v("#")]),t._v(" 5.2: Snippets of App User Interface")]),t._v(" "),s("p",[t._v("User interface for the mobile application is shown in the upcoming pictures.")]),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr"),t._v(" "),s("p",[s("img",{attrs:{src:"/thesis/classifier-graph.png",alt:"Graph of all Classes and their Identifications",title:"Graph of all Classes and their Identifications"}})]),t._v(" "),s("hr"),t._v(" "),s("span",{staticStyle:{"text-align":"center",display:"block"}},[s("strong",[t._v("Figure 4.4:")]),t._v(" Graph of all Classes and their Identifications")]),t._v(" "),s("hr")])}),[],!1,null,null,null);a.default=n.exports}}]);