<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Table of Content | Plantlet</title>
    <meta name="generator" content="VuePress 1.5.3" />
    <link rel="icon" href="/favicon.svg" />
    <meta
      name="description"
      content="Detection of disease in plants using deep learning"
    />
    <link rel="preload" href="assets/css/0.styles.83afb7de.css" as="style" />
    <link rel="preload" href="assets/js/app.f399cf66.js" as="script" />
    <link rel="preload" href="assets/js/2.ebead725.js" as="script" />
    <link rel="preload" href="assets/js/6.5355300d.js" as="script" />
    <link rel="prefetch" href="assets/js/3.37a74d58.js" />
    <link rel="prefetch" href="assets/js/4.3b6a7e49.js" />
    <link rel="prefetch" href="assets/js/5.af75ae8c.js" />
    <link rel="stylesheet" href="assets/css/0.styles.83afb7de.css" />
  </head>
  <body>
    <div id="app" data-server-rendered="true">
      <div class="theme-container">
        <header class="navbar">
          <div class="sidebar-button">
            <svg
              xmlns="http://www.w3.org/2000/svg"
              aria-hidden="true"
              role="img"
              viewBox="0 0 448 512"
              class="icon"
            >
              <path
                fill="currentColor"
                d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"
              ></path>
            </svg>
          </div>
          <a href="/" class="home-link router-link-active"
            ><!---->
            <span class="site-name">Plantlet</span></a
          >
          <div class="links">
            <div class="search-box">
              <input
                aria-label="Search"
                autocomplete="off"
                spellcheck="false"
                value=""
              />
              <!---->
            </div>
            <nav class="nav-links can-hide">
              <div class="nav-item">
                <a href="/" class="nav-link"> Home </a>
              </div>
              <div class="nav-item">
                <a href="/thesis/thesis/" class="nav-link"> Thesis </a>
              </div>
              <div class="nav-item">
                <a
                  href="https://cutt.ly/FaHO7kM"
                  target="_blank"
                  rel="noopener noreferrer"
                  class="nav-link external"
                >
                  Download APK
                  <svg
                    xmlns="http://www.w3.org/2000/svg"
                    aria-hidden="true"
                    x="0px"
                    y="0px"
                    viewBox="0 0 100 100"
                    width="15"
                    height="15"
                    class="icon outbound"
                  >
                    <path
                      fill="currentColor"
                      d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"
                    ></path>
                    <polygon
                      fill="currentColor"
                      points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"
                    ></polygon></svg
                ></a>
              </div>
              <div class="nav-item">
                <a
                  href="https://github.com/muhammadosmanali/fyp-project"
                  target="_blank"
                  rel="noopener noreferrer"
                  class="nav-link external"
                >
                  Source Code
                  <svg
                    xmlns="http://www.w3.org/2000/svg"
                    aria-hidden="true"
                    x="0px"
                    y="0px"
                    viewBox="0 0 100 100"
                    width="15"
                    height="15"
                    class="icon outbound"
                  >
                    <path
                      fill="currentColor"
                      d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"
                    ></path>
                    <polygon
                      fill="currentColor"
                      points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"
                    ></polygon></svg
                ></a>
              </div>
              <!---->
            </nav>
          </div>
        </header>
        <div class="sidebar-mask"></div>
        <aside class="sidebar">
          <nav class="nav-links">
            <div class="nav-item"><a href="/" class="nav-link"> Home </a></div>
            <div class="nav-item">
              <a href="/thesis/thesis/" class="nav-link"> Thesis </a>
            </div>
            <div class="nav-item">
              <a
                href="https://cutt.ly/FaHO7kM"
                target="_blank"
                rel="noopener noreferrer"
                class="nav-link external"
              >
                Download APK
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  aria-hidden="true"
                  x="0px"
                  y="0px"
                  viewBox="0 0 100 100"
                  width="15"
                  height="15"
                  class="icon outbound"
                >
                  <path
                    fill="currentColor"
                    d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"
                  ></path>
                  <polygon
                    fill="currentColor"
                    points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"
                  ></polygon></svg
              ></a>
            </div>
            <div class="nav-item">
              <a
                href="https://github.com/muhammadosmanali/fyp-project"
                target="_blank"
                rel="noopener noreferrer"
                class="nav-link external"
              >
                Source Code
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  aria-hidden="true"
                  x="0px"
                  y="0px"
                  viewBox="0 0 100 100"
                  width="15"
                  height="15"
                  class="icon outbound"
                >
                  <path
                    fill="currentColor"
                    d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"
                  ></path>
                  <polygon
                    fill="currentColor"
                    points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"
                  ></polygon></svg
              ></a>
            </div>
            <!---->
          </nav>
          <ul class="sidebar-links">
            <li>
              <a href="/thesis/" aria-current="page" class="active sidebar-link"
                >Table of Content</a
              >
              <ul class="sidebar-sub-headers">
                <li class="sidebar-sub-header">
                  <a href="/thesis/#abbreviations" class="sidebar-link"
                    >Abbreviations</a
                  >
                </li>
                <li class="sidebar-sub-header">
                  <a href="/thesis/#abstract" class="sidebar-link">Abstract</a>
                </li>
                <li class="sidebar-sub-header">
                  <a href="/thesis/#chapter-1-introduction" class="sidebar-link"
                    >Chapter 1: Introduction</a
                  >
                </li>
                <li class="sidebar-sub-header">
                  <a
                    href="/thesis/#chapter-2-motivation-and-problem-statement"
                    class="sidebar-link"
                    >Chapter 2: Motivation and Problem Statement</a
                  >
                </li>
                <li class="sidebar-sub-header">
                  <a
                    href="/thesis/#chapter-3-literature-review"
                    class="sidebar-link"
                    >Chapter 3: Literature Review</a
                  >
                </li>
                <li class="sidebar-sub-header">
                  <a
                    href="/thesis/#chapter-4-materials-and-methods"
                    class="sidebar-link"
                    >Chapter 4: Materials and Methods</a
                  >
                </li>
                <li class="sidebar-sub-header">
                  <a
                    href="/thesis/#chapter-5-implementation-details"
                    class="sidebar-link"
                    >Chapter 5: Implementation Details</a
                  >
                </li>
              </ul>
            </li>
          </ul>
        </aside>
        <main class="page">
          <div class="theme-default-content content__default">
            <h1 id="table-of-content">
              <a href="#table-of-content" class="header-anchor">#</a> Table of
              Content
            </h1>
            <p></p>
            <div class="table-of-contents">
              <ul>
                <li><a href="#abbreviations">Abbreviations</a></li>
                <li><a href="#abstract">Abstract</a></li>
                <li>
                  <a href="#chapter-1-introduction">Chapter 1: Introduction</a>
                </li>
                <li>
                  <a href="#chapter-2-motivation-and-problem-statement"
                    >Chapter 2: Motivation and Problem Statement</a
                  >
                  <ul>
                    <li><a href="#_2-1-motivation">2.1: Motivation</a></li>
                    <li>
                      <a href="#_2-2-problem-statement"
                        >2.2: Problem Statement</a
                      >
                    </li>
                  </ul>
                </li>
                <li>
                  <a href="#chapter-3-literature-review"
                    >Chapter 3: Literature Review</a
                  >
                </li>
                <li>
                  <a href="#chapter-4-materials-and-methods"
                    >Chapter 4: Materials and Methods</a
                  >
                  <ul>
                    <li><a href="#_4-1-materials">4.1: Materials</a></li>
                    <li><a href="#_4-2-methods">4.2: Methods</a></li>
                  </ul>
                </li>
                <li>
                  <a href="#chapter-5-implementation-details"
                    >Chapter 5: Implementation Details</a
                  >
                  <ul>
                    <li>
                      <a href="#_5-1-snippets-of-model-training-code"
                        >5.1: Snippets of Model Training Code</a
                      >
                    </li>
                    <li>
                      <a href="#_5-2-snippets-of-app-user-interface"
                        >5.2: Snippets of App User Interface</a
                      >
                    </li>
                  </ul>
                </li>
              </ul>
            </div>
            <p></p>
            <h2 id="abbreviations">
              <a href="#abbreviations" class="header-anchor">#</a> Abbreviations
            </h2>
            <p>
              <strong>ML</strong> Machine Learning<br />
              <strong>DL</strong> Deep Learning<br />
              <strong>CNN</strong> Convolutional Neural Network<br />
              <strong>DCNN</strong> Deep Convolutional Neural Network<br />
              <strong>ILSVRC</strong> ImageNet Large Scale Visual Recognition
              Challenge<br />
              <strong>VGG</strong> Visual Geometry Group
              <strong>(</strong> Convolutional neural network architecture
              <strong>)</strong><br />
              <strong>COCO</strong> Common Objects in Context
            </p>
            <h2 id="abstract">
              <a href="#abstract" class="header-anchor">#</a> Abstract
            </h2>
            <p>
              With the increase in population, the needs have also been
              increased. As agriculture is a vital source for providing food,
              whereas crop ailments are major commination to agriculture, and
              their early detection remains strenuous over the globe due to
              insufficient technology, agricultural organizations are unable to
              reach farmers in time for necessary precautionary measures. As a
              result, farmers have to suffer from compromised lower crop yield.
              Many machine learning models were used to detect and identify
              diseases of plants but, after the advancement in Deep Learning,
              this field seems to have great potential concerning improved
              accuracy. The combination of advancements in computer vision and
              the global smartphone penetration made possible by deep learning
              to provide a mobile-phone-based system to diagnose diseases. Using
              a public data-set of <strong>87,900</strong> photos of healthy and
              diseased leaves, several models were trained to identify
              <strong>14</strong> crops and the presence or absence of
              <strong>26</strong> diseases, with the best performance reaching a
              <strong>98.58%</strong> on the retained dataset, which
              demonstrates the practicality of our perspective. Generally, the
              methodology of training deep convolutional neural networks on
              exceptionally huge and publicly accessible image data-sets
              presents a straightforward path towards a massive global diagnosis
              of mobile-phone-assisted crop disease.
            </p>
            <h2 id="chapter-1-introduction">
              <a href="#chapter-1-introduction" class="header-anchor">#</a>
              Chapter 1: Introduction
            </h2>
            <p>
              Earth is occupying more than 7 billion people. The number is
              increasing gradually. With a persistent increase in population, it
              is understood that basic life necessities are also increasing in
              which food is on top of the list. The increasing population has
              also eaten up the land, and the area for agricultural land is
              shrinking up. So we have to get an adequate amount of food from
              the land available. Food sustainability, however, remains endanger
              by a variety of factors which includes climate change [5], plant
              diseases [23] and others. When the plants are growing up, they are
              attacked by diseases which clearly means a compromised lower crop
              yield. Unfortunately, smallholder farmers have to face the
              disastrous consequences whose income entirely depends upon crops.
              Yield. The major agricultural production comes from smallholder
              farmers [9], and they have to suffer approximately 50% yield loss
              due to climate change, pest attack, and diseases. Acknowledging
              these problems, various attempts have been made to avert or lower
              the loss of crop yield. To prevent the disease, it is crucial to
              detect the disease at an early stage. And efficient disease
              management is a very crucial step in this regard. Agricultural
              organizations have been working for disease detection at an early
              stage at local clinics. During the past decades the world has
              totally turned into ”Global Village” and because of that enormous
              data is available online including information on disease
              diagnosis [11] and the leverage of which is internet penetration
              worldwide. More recently, mobile phone technology incredibly has
              become famous due to the proliferation of mobile-based tools in
              all parts of the world. All these factors escort us to a point
              where disease detection is technically feasible and available at
              an unparalleled scale. Unlike other countries, Pakistan lacks
              modern technology due to which, we are unable to detect diseases
              in time and to reach farmers in order to raise awareness about
              rehabilitation. The blue-collar approaches make it very slow for
              policy-making organizations to gather data and draw results for
              immediate movement. The intensity behind this research work is to
              dispense an efficient system that can detect the disease
              straight-away whether a farmer or agricultural organization uses
              it. We intended to develop mobile as well as a web-based tool
              using deep learning for the detection of crop diseases. Deep
              learning has proved its worth successfully in many different
              domains such as end-to-end learning. Now we are going to
              demonstrate the technical feasibility of our proposed approach by
              utilizing 87,900 images on healthy and infected leaves of crop
              plants that are openly available on the online system PlantVillage
              [2].
            </p>
            <p>
              <img
                src="/thesis/ExampleDatasetImages.jpg"
                alt="Sample leaf images from the dataset"
                title="Sample leaf images from the dataset"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 1.1:</strong> Sample leaf images from the
              dataset</span
            >
            <hr />
            <p>
              A DCNN includes the mapping between an input to an output. Deep
              learning is probability-based means it never gives us the definite
              answer however it gives us the probabilities. The term CNN itself
              stipulates that a mathematical function called convolution is used
              within the network. Convolution is a specific type mathematical
              operation on two functions which produces a third function that
              expresses how another changes one’s form. A CNN consists of two
              main input and output layers, and multiple hidden layers.
              Typically the hidden layers consist of a series of convolutionary
              layers. The activation function is commonly a Rectified Linear
              Units (RELU). The purpose of RELU is to normalize the values after
              the application of convolution to convert the values in a specific
              range. Additional convolutions such as pooling, fully connected
              layers and normalization layers follow the RELU. Pooling is to
              choose the best or one thing out of the pool of things. The nodes
              in neural networks are computational units which take weighted
              inputs from the incoming edges and provide an outgoing edge with
              numerical output. node enumerates an output value by adding a
              specific function to the previous layer’s input values. In a
              neural network, model learning progresses through iterative
              changes to these weights and biases. DCNN is learned by changing
              network parameters in such a way as to improve mapping during the
              training. For thepurpose of plant disease identification, we
              needed a large and verified data-set of healthy and diseased
              images to train an accurate image classifier, but such dataset did
              not exist until very recently, and even small dataset were not
              publicly available. In order to tackle this issue, the
              PlantVillage project began to collect a large dataset of diseased
              and healthy crop plants and made them available publicly. We
              announce here on the classification of 26 diseases (presence or
              absence) in 14 crop species using 87,900 with deep learning (DL).
            </p>
            <h2 id="chapter-2-motivation-and-problem-statement">
              <a
                href="#chapter-2-motivation-and-problem-statement"
                class="header-anchor"
                >#</a
              >
              Chapter 2: Motivation and Problem Statement
            </h2>
            <h3 id="_2-1-motivation">
              <a href="#_2-1-motivation" class="header-anchor">#</a> 2.1:
              Motivation
            </h3>
            <p>
              With the increase in population, the needs have also been
              increased. As agriculture is the vital source for providing food
              but, unfortunately, because of lack the modern technology, the
              agricultural organization are unable to reach farmers in time for
              necessary precautionary measures. As a results farmers have to
              suffer from compromised lower crop yield. We are aimed to work for
              a solution that can prevent farmers from suffering a loss to some
              extent.
            </p>
            <h3 id="_2-2-problem-statement">
              <a href="#_2-2-problem-statement" class="header-anchor">#</a> 2.2:
              Problem Statement
            </h3>
            <p>
              Plant disease affects not only the production of human food but
              also natural systems. The majority of smallholder farmers do not
              have access to the resources that can identify the diseases
              accurately and timely. Due to the lack of timely and accurate
              agricultural information, they have to suffer from lower crop
              yield.
            </p>
            <h2 id="chapter-3-literature-review">
              <a href="#chapter-3-literature-review" class="header-anchor">#</a>
              Chapter 3: Literature Review
            </h2>
            <p>
              The Deep Learning (DL) is subcategory of ML. This field is still
              evolving. Machine Learning has made enormous evolution in the past
              few years. Many advances were found in the first phase, such as
              handwritten text recognition, back-propagation and resolving
              training problems. In the second phase was to develop algorithms
              for health-sectors, text-recognition, earthquake-predictions,
              marketing, finance, image-recognition, and object detection. In
              2012 a deep convolutionary neural network accomplished a top-5
              error of 15.3% when classifying images into 1000 possible
              categories [1]. In the next three years, numerous advances in
              convolutionary neural networks reduced the error rate to 3.57.
              With the passage of time as Deep Learning architectures started to
              evolve, researchers applied them to classification, segmentation,
              object detection, video processing, natural language processing,
              image recognition, and speech recognition. Different agriculture
              application has also been developed using these architectures. For
              example, Leaf counting was performed using Deep CNN with average
              accuracy of 95% [25]. Leaf classification was performed using deep
              convolutional neural network classifier among 32 different species
              with average accuracy of 97.3% [7]. Fruit counting was performed
              by using simulated deep convolutional neural network with an
              average accuracy of 91% [19]. Classification of land cover and
              crop type was performed by using deep learning classifier with
              accuracy of crop type identification of 95% [18]. Identification
              of plants was performed by using Deep convolutional neural network
              [10, 16]. In [26] identification of plants was performed among 100
              different species utilizing 10,000 images using deep learning with
              an accuracy of 91.78%. In addition deep learning techniques are
              also used in for crucial tasks such as crop plant disease
              identification and classification which is main topic of this
              thesis. For example, in [20] plant disease detection was performed
              using deep convolutional neural network classifier. To sum up,
              used DL Architectures are shown in the table along with the
              selected plants and their results.
            </p>
            <table>
              <thead>
                <tr>
                  <th>Deep Learning Techniques</th>
                  <th>Dataset</th>
                  <th>Used Plants</th>
                  <th>Accuracy</th>
                  <th>Reference</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Convolutional Neural Network</td>
                  <td>Plant Village</td>
                  <td>Maize</td>
                  <td>92.85%</td>
                  <td>[21]</td>
                </tr>
                <tr>
                  <td>LeNet</td>
                  <td>Plant Village</td>
                  <td>Banana</td>
                  <td>98.54%</td>
                  <td>[4]</td>
                </tr>
                <tr>
                  <td>
                    Alex-Net, VGG16, VGG-19, Squeeze-Net, Goog-LeNet,
                    Inception-v-3, Inception-ResNet-v-2, ResNet-50, Resnet-101
                  </td>
                  <td>Real Field Dataset</td>
                  <td>Apricot, Walnut, Peach, Cherry</td>
                  <td>97.14%</td>
                  <td>[24]</td>
                </tr>
                <tr>
                  <td>Inception-v-3</td>
                  <td>Experimental Field Dataset</td>
                  <td>Cassava</td>
                  <td>93%</td>
                  <td>[3]</td>
                </tr>
                <tr>
                  <td>Convolutional Neural Network</td>
                  <td>Images Taken From The Research Center</td>
                  <td>Cucumber</td>
                  <td>82.3%</td>
                  <td>[8]</td>
                </tr>
                <tr>
                  <td>Super Resolution Convolutional Neural Network (SCRNN)</td>
                  <td>Plant Village</td>
                  <td>Tomato</td>
                  <td>90%</td>
                  <td>[15]</td>
                </tr>
                <tr>
                  <td>Caffe-Net</td>
                  <td>Downloaded From The Internet</td>
                  <td>Pear, cherry, peach, apple, grapevine</td>
                  <td>96.3%</td>
                  <td>[22]</td>
                </tr>
                <tr>
                  <td>Resnet-50, Inception-V-2, Mobile-Net-V-1</td>
                  <td>Real Environment</td>
                  <td>Banana</td>
                  <td>99% of ResNet-50</td>
                  <td>[17]</td>
                </tr>
                <tr>
                  <td>Mobile-Net, Modified-Mobile-Net, Reduced-Mobile-Net</td>
                  <td>Plant Village dataset</td>
                  <td>24 Types Of Plants</td>
                  <td>98.34% of reduced MobileNet</td>
                  <td>[14]</td>
                </tr>
              </tbody>
            </table>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Table 3.1:</strong> DL Architectures along with selected
              plant species and results</span
            >
            <hr />
            <p>
              From this table, we can conclude that while some Deep Learning
              Architectures/- Models have been developed for the identification
              of the diseases of plants but this is still a prolific research
              field and should lead to improvements for better plant disease
              identification. So we needed a large and verified data set of
              healthy and diseased images to train an accurate image classifier
              for plant disease diagnosis, but such a dataset did not exist
              until very recently. Plant Village collected a huge dataset of
              87,900 images of plant health to enable the development of
              smartphone assisted disease diagnosis and made it publicly and
              freely available [12].
            </p>
            <h2 id="chapter-4-materials-and-methods">
              <a href="#chapter-4-materials-and-methods" class="header-anchor"
                >#</a
              >
              Chapter 4: Materials and Methods
            </h2>
            <h3 id="_4-1-materials">
              <a href="#_4-1-materials" class="header-anchor">#</a> 4.1:
              Materials
            </h3>
            <p>
              Our dataset is consists of 87,900 pictures of healthy and diseased
              plant leaves. All the images in the dataset were taken at
              experimental research stations affiliated with Land Grant
              Universities in the USA (Penn State, Florida State, Cornell, and
              others) [12]. These images consist of 26 major crop diseases (4
              bacterial diseases, 17 Fungal diseases, 2 viral diseases, 2 mold
              diseases, and 1 disease caused by a mite). These images also have
              12 healthy leaves of 12 crop species that are not visibly affected
              by a disease. Table 4.1 Summarizes the dataset.
            </p>
            <table>
              <thead>
                <tr>
                  <th>Crop</th>
                  <th>Classes</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Apple</td>
                  <td>
                    Apple-Healthy, Apple-Cedar-Rust, Apple-Black-Rot, Apple-Scab
                  </td>
                </tr>
                <tr>
                  <td>Raspberry</td>
                  <td>Raspberry-Healthy</td>
                </tr>
                <tr>
                  <td>Soybean</td>
                  <td>Soybean-Healthy</td>
                </tr>
                <tr>
                  <td>Squash</td>
                  <td>Squash-Powdery-Mildew</td>
                </tr>
                <tr>
                  <td>Strawberry</td>
                  <td>Strawberry-Leaf-Scorch, Strawberry-Healthy</td>
                </tr>
                <tr>
                  <td>Tomato</td>
                  <td>
                    Tomato-Healthy, Tomato-Late-Blight, TomatoBacterial-Spot,
                    Tomato-Early-Blight, TomatoLeaf-Mold,
                    Tomato-Septoria-Leaf-Spot, TomatoMosaic-Virus,
                    Tomato-Two-Spotted-Spider-Mite, Tomato-Target-Spot,
                    Tomato-Yellow-Leaf-CurlVirus
                  </td>
                </tr>
                <tr>
                  <td>Potato</td>
                  <td>
                    Potato-Early-Blight, Potato-Late-Blight, PotatoHealthy
                  </td>
                </tr>
                <tr>
                  <td>Blueberry</td>
                  <td>Blueberry-Healthy</td>
                </tr>
                <tr>
                  <td>Cherry</td>
                  <td>Cherry-Healthy, Cherry-Powdery-Mildew</td>
                </tr>
                <tr>
                  <td>Corn</td>
                  <td>
                    Corn-Healthy, Corn-Common-Rust, Corn-Gray-Leaf Spot,
                    Corn-Northern-Leaf-Blight
                  </td>
                </tr>
                <tr>
                  <td></td>
                  <td></td>
                </tr>
                <tr>
                  <td>Grape</td>
                  <td>
                    Grape-Healthy, Grape-Leaf-Blight, Grape-BlackRot,
                    Grape-Black-Measles(Esca)
                  </td>
                </tr>
                <tr>
                  <td>Orange</td>
                  <td>Orange-Huanglongbing (Citrus-Greening)</td>
                </tr>
                <tr>
                  <td>Peach</td>
                  <td>Peach-Healthy, Peach-Bacterial-Spot</td>
                </tr>
                <tr>
                  <td>Bell-Pepper</td>
                  <td>Bell-Pepper-Bacterial-Spot, Bell-Pepper-Healthy</td>
                </tr>
              </tbody>
            </table>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Table 4.1:</strong> List of Crops with their respective
              classes in the Dataset.</span
            >
            <hr />
            <h3 id="_4-2-methods">
              <a href="#_4-2-methods" class="header-anchor">#</a> 4.2: Methods
            </h3>
            <p>
              Since these diseases can severely affect plants, we landed up with
              four different models for 38 different classes (Table 4.1) to
              achieve maximum accuracy. Blueprint of our proposed system for
              disease detection is showed in the figure 4.1.
            </p>
            <p>
              To train the model, we focused on 4 different architectures,
              namely VGG16, Resnet152, MobileNet, and MobileNetV2.
            </p>
            <p>
              VGG16 was proposed by Andrew Zisserman and Karen Simonyan of the
              Visual Geometry Community Lab at Oxford University. This model
              secured 1st and 2nd place in ImageNet Large Scale Visual
              Recognition Challenge (ILSVRC) in 2014. The VGG16 network is
              trained on an ImageNet dataset which has 14 million images and
              1000 classes, and this model achieves 92.7% top-5 test accuracy.
            </p>
            <p>
              Resnet was proposed by Microsoft Research Asia [13] and won the
              ImageNet Large Scale Visual Recognition Challenge (ILSVRC) and
              MS-COCO competition in 2015. ResNet architecture has several
              variants all of them have the similar concept but have different
              number of layers, for example ResNet-18, ResNet-50, ResNet-101 and
              so on. The name Resnet followed by numbers simply insinuate the
              Resnet architecture witch has number of layers of neural network.
              The main idea manoeuvred in these models, residual network
              connections, is found to greatly enhance gradient flow, thus
              enabling the training of tens or even hundreds of layers of much
              deeper models.
            </p>
            <p>
              <img
                src="/thesis/fyp_model_image.jpeg"
                alt="Blueprint of our proposed system for disease detection"
                title="Blueprint of our proposed system for disease detection"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.1:</strong> Blueprint of our proposed system for
              disease detection</span
            >
            <hr />
            <p>
              MobileNet is a model built primarily from depthwise separable
              convolutions to create lightweight deep convolutional neural
              networks and provides an efficient model for smartphone and
              integrated vision applications [6].
            </p>
            <p>
              To train these models we used Google Colaboratory framework.
              Google Colab is a free cloud service created by Google, in which
              the person who has a Gmail account can write, execute codes for
              Machine learning as well as for Deep learning. In Google Colab
              different runtime environments and Various versions of python are
              available. It can also download large datasets to google drive at
              higher speed directly from the servers. With Google Colab, you can
              also mount your drive and it can fetch the appropriate file after
              the authentication. The most important feature of Google Colab
              that distinguishes it from other free cloud services is it
              provides GPU and it is totally free. To summarize, we have 4
              experimental configurations in total, which are described in the
              next section
            </p>
            <h4 id="_4-2-1-experiment-1">
              <a href="#_4-2-1-experiment-1" class="header-anchor">#</a> 4.2.1:
              Experiment # 1
            </h4>
            <p>
              In this experiment, we used a python deep learning library called
              PyTorch, and the model we used in this experiment is Resnet152. We
              used transfer learning to train the model because it always yields
              better results. This experiment runs for a total of 50 epochs and
              achieves testing accuracy of 98.5%.
            </p>
            <p>
              <img
                src="/thesis/fyp-model-accuracy-pytorch.png"
                alt="Model Accuracy"
                title="Model Accuracy"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.2:</strong> Model Accuracy</span
            >
            <hr />
            <p>
              <img
                src="/thesis/fyp-model-loss-pytorch.png"
                alt="Model Loss"
                title="Model Loss"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.3:</strong> Model Loss</span
            >
            <hr />
            <h4 id="_4-2-2-experiment-2">
              <a href="#_4-2-2-experiment-2" class="header-anchor">#</a> 4.2.2:
              Experiment # 2
            </h4>
            <p>
              In this experiment, we used a python deep learning library called
              TensorFlow, and we created a custom model. This experiment runs
              for a total of 80 epochs and achieves an accuracy of 94.72%.
            </p>
            <p>
              <img
                src="/thesis/precision-recall-accuracy-f1-score-custome-model.png"
                alt="Accuracy of the classifier for all classes"
                title="Accuracy of the classifier for all classes"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Accuracy of the classifier for all
              classes</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <h2 id="chapter-5-implementation-details">
              <a href="#chapter-5-implementation-details" class="header-anchor"
                >#</a
              >
              Chapter 5: Implementation Details
            </h2>
            <p>
              The very first was to gather the data and train the model to get
              the results. After the collection of the dataset which is
              consisted of 87,900 different plant images, we divided the dataset
              into train-test splits of 25-75, 50-50, and 25-75. We made these
              splits to get a sense of how our proposed approach will perform on
              the unseen data and also keep track of if our proposed approach is
              underfitting or overfitting. After training the model with the
              best performance reaching a 98.58% on a held-out test set we
              developed an API using Flask for this model to interact with our
              mobile application. After the development of the API, we developed
              a mobile application to interact with the API which interacts with
              the model to give the final results.
            </p>
            <h3 id="_5-1-snippets-of-model-training-code">
              <a
                href="#_5-1-snippets-of-model-training-code"
                class="header-anchor"
                >#</a
              >
              5.1: Snippets of Model Training Code
            </h3>
            <p>Here are some snippets of our code to train the model.</p>
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms<span class="token punctuation">,</span> models
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> lr_scheduler
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.1:</strong> Libraries used in the model
              training</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code>data_dir <span class="token operator">=</span> <span class="token string">'/content/DataSet'</span>
train_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/train'</span>
valid_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/val'</span>
nThreads <span class="token operator">=</span> <span class="token number">4</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.2:</strong> Load the dataset</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code>data_transforms <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'train'</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
        transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'val'</span><span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
        transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

data_dir <span class="token operator">=</span> <span class="token string">'/content/DataSet'</span>
image_datasets <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                          data_transforms<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span>
                  <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

dataloaders <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                             shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
              <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

dataset_sizes <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

class_names <span class="token operator">=</span> image_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>classes
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.3:</strong> Applying Data Augmentation</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code>model <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet152<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>

<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict

classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
                          <span class="token punctuation">(</span><span class="token string">'fc1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          <span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          <span class="token punctuation">(</span><span class="token string">'fc2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          <span class="token punctuation">(</span><span class="token string">'output'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                          <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fc <span class="token operator">=</span> classifier
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.4:</strong> Building the Classifier</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code><span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> scheduler<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    since <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    best_model_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    best_acc <span class="token operator">=</span> <span class="token number">0.0</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch {}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> phase <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
                scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>  
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  

            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
            running_corrects <span class="token operator">=</span> <span class="token number">0</span>

            <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> dataloaders<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">:</span>
                inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span>phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
                    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
                    _<span class="token punctuation">,</span> preds <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

                    <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
                        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
                        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

                running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                running_corrects <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

            epoch_loss <span class="token operator">=</span> running_loss <span class="token operator">/</span> dataset_sizes<span class="token punctuation">[</span>phase<span class="token punctuation">]</span>
            epoch_acc <span class="token operator">=</span> running_corrects<span class="token punctuation">.</span>double<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> dataset_sizes<span class="token punctuation">[</span>phase<span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{} Loss: {:.4f} Acc: {:.4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                phase<span class="token punctuation">,</span> epoch_loss<span class="token punctuation">,</span> epoch_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'val'</span> <span class="token keyword">and</span> epoch_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>
                best_acc <span class="token operator">=</span> epoch_acc
                best_model_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    time_elapsed <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> since
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training complete in {:.0f}m {:.0f}s'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
        time_elapsed <span class="token operator">//</span> <span class="token number">60</span><span class="token punctuation">,</span> time_elapsed <span class="token operator">%</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best valid accuracy: {:4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>best_model_wts<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.5:</strong> Function to train the model</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code>num_epochs <span class="token operator">=</span> <span class="token number">80</span>

criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
exp_lr_scheduler <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
model_ft <span class="token operator">=</span> train_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> exp_lr_scheduler<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">)</span>
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.6:</strong> : Start Training</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloaders<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
  model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  accuracy <span class="token operator">=</span> <span class="token number">0</span>
  model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    
  <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> dataloaders<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    images <span class="token operator">=</span> Variable<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    labels <span class="token operator">=</span> Variable<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    output <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    ps <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
    equality <span class="token operator">=</span> <span class="token punctuation">(</span>labels<span class="token punctuation">.</span>data <span class="token operator">==</span> ps<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    accuracy <span class="token operator">+=</span> equality<span class="token punctuation">.</span>type_as<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Testing Accuracy: {:.3f}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>accuracy<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloaders<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloaders<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.7:</strong> Model validation after
              Training</span
            >
            <hr />
            <div class="language-py extra-class">
              <pre
                class="language-py"
              ><code>model<span class="token punctuation">.</span>class_to_idx <span class="token operator">=</span> dataloaders<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>class_to_idx
model<span class="token punctuation">.</span>epochs <span class="token operator">=</span> num_epochs
checkpoint <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'input_size'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token string">'batch_size'</span><span class="token punctuation">:</span> dataloaders<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
                  <span class="token string">'output_size'</span><span class="token punctuation">:</span> <span class="token number">39</span><span class="token punctuation">,</span>
                  <span class="token string">'state_dict'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  <span class="token string">'data_transforms'</span><span class="token punctuation">:</span> data_transforms<span class="token punctuation">,</span>
                  <span class="token string">'optimizer_dict'</span><span class="token punctuation">:</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  <span class="token string">'class_to_idx'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>class_to_idx<span class="token punctuation">,</span>
                  <span class="token string">'epoch'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>epochs<span class="token punctuation">}</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> <span class="token string">'plants9615_checkpoint.pth'</span><span class="token punctuation">)</span>
</code></pre>
            </div>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 5.8:</strong> Saving the model for Further
              use</span
            >
            <hr />
            <h3 id="_5-2-snippets-of-app-user-interface">
              <a
                href="#_5-2-snippets-of-app-user-interface"
                class="header-anchor"
                >#</a
              >
              5.2: Snippets of App User Interface
            </h3>
            <p>
              User interface for the mobile application is shown in the upcoming
              pictures.
            </p>
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
            <p>
              <img
                src="/thesis/classifier-graph.png"
                alt="Graph of all Classes and their Identifications"
                title="Graph of all Classes and their Identifications"
              />
            </p>
            <hr />
            <span style="text-align: center; display: block"
              ><strong>Figure 4.4:</strong> Graph of all Classes and their
              Identifications</span
            >
            <hr />
          </div>
          <footer class="page-edit">
            <!---->
            <!---->
          </footer>
          <!---->
        </main>
      </div>
      <div class="global-ui"></div>
    </div>
    <script src="assets/js/app.f399cf66.js" defer></script>
    <script src="assets/js/2.ebead725.js" defer></script>
    <script src="assets/js/6.5355300d.js" defer></script>
  </body>
</html>
